# æ¨ç†æµç¨‹è¯¦è§£

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜ RFdiffusion åœ¨æ¨ç†æ—¶çš„å®Œæ•´æ‰§è¡Œæµç¨‹ã€‚

## ğŸ¯ æ€»ä½“æµç¨‹

```
ç”¨æˆ·å‘½ä»¤ â†’ å‚æ•°è§£æ â†’ æ¨¡å‹åŠ è½½ â†’ åˆå§‹åŒ– â†’ é‡‡æ ·å¾ªç¯ â†’ åå¤„ç† â†’ è¾“å‡º
```

---

## ğŸ“ ç¬¬ä¸€æ­¥ï¼šå‘½ä»¤è¡Œè°ƒç”¨

### å…¸å‹å‘½ä»¤

```bash
python scripts/run_inference.py \
    inference.output_prefix=output/design \
    inference.input_pdb=target.pdb \
    'contigmap.contigs=[A1-100/0 50-100]' \
    inference.num_designs=10 \
    inference.ckpt_override_path=models/Base_ckpt.pt
```

### å‚æ•°è¯´æ˜

| å‚æ•° | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| `output_prefix` | è¾“å‡ºæ–‡ä»¶å‰ç¼€ | `output/my_design` |
| `input_pdb` | è¾“å…¥PDBæ–‡ä»¶ï¼ˆå¯é€‰ï¼‰ | `1abc.pdb` |
| `contigs` | åºåˆ—æ˜ å°„å®šä¹‰ | `[A1-50/0 100-150]` |
| `num_designs` | ç”Ÿæˆæ•°é‡ | `10` |
| `ckpt_override_path` | æ¨¡å‹æƒé‡æ–‡ä»¶ | `Base_ckpt.pt` |
| `potentials` | å¼•å¯¼åŠ¿èƒ½ | `binder_ROG:1.0` |

### Contig è¯­æ³•

```
æ ¼å¼: [chain_start-end/insertion_length ...]

ç¤ºä¾‹:
'A1-100/0'        # Aé“¾1-100æ®‹åŸºï¼Œå›ºå®šï¼ˆæ’å…¥0ï¼‰
'50-100'          # è®¾è®¡50-100ä¸ªæ®‹åŸº
'B5-20/0 20'      # Bé“¾5-20å›ºå®šï¼Œç„¶åè®¾è®¡20ä¸ªæ®‹åŸº
'A1-10/10-20'     # Aé“¾1-10å›ºå®šï¼Œè®¾è®¡10-20ä¸ªæ®‹åŸº
```

---

## ğŸ—ï¸ ç¬¬äºŒæ­¥ï¼šåˆå§‹åŒ–

### 2.1 å‚æ•°è§£æå’Œé…ç½®

```python
# scripts/run_inference.py

def main():
    # 1. åŠ è½½é…ç½®æ–‡ä»¶
    config = OmegaConf.load('config/inference.yaml')

    # 2. å‘½ä»¤è¡Œè¦†ç›–
    cli_config = OmegaConf.from_cli()
    config = OmegaConf.merge(config, cli_config)

    # 3. éªŒè¯å‚æ•°
    validate_config(config)
```

**å…³é”®é…ç½®é¡¹**:
```yaml
inference:
  num_designs: 10           # ç”Ÿæˆå¤šå°‘ä¸ªè®¾è®¡
  ckpt_override_path: ...   # æ¨¡å‹è·¯å¾„
  num_steps: 50             # å»å™ªæ­¥æ•°
  temperature: 1.0          # é‡‡æ ·æ¸©åº¦

diffuser:
  T: 200                    # è®­ç»ƒæ—¶çš„æ‰©æ•£æ­¥æ•°
  schedule: linear          # å™ªå£°è°ƒåº¦

model:
  n_layers: 24              # æ¨¡å‹å±‚æ•°
  n_head: 16                # æ³¨æ„åŠ›å¤´æ•°
```

### 2.2 æ¨¡å‹åŠ è½½

```python
# inference/model_runners.py

class Sampler:
    def __init__(self, conf):
        # 1. åˆ›å»ºæ¨¡å‹
        self.model = RoseTTAFoldModule(
            n_layers=conf.model.n_layers,
            # ... å…¶ä»–å‚æ•°
        )

        # 2. åŠ è½½æƒé‡
        checkpoint = torch.load(conf.inference.ckpt_override_path)
        self.model.load_state_dict(checkpoint['model_state_dict'])

        # 3. è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        self.model.eval()

        # 4. ç§»è‡³GPU
        self.model = self.model.to('cuda')

        # 5. åˆ›å»ºæ‰©æ•£å™¨
        self.diffuser = Diffuser(T=200)
```

### 2.3 è¾“å…¥å¤„ç†

```python
def load_input_data(conf):
    """å¤„ç†è¾“å…¥PDBå’Œcontigå®šä¹‰"""

    # 1. è§£æPDBï¼ˆå¦‚æœæä¾›ï¼‰
    if conf.inference.input_pdb:
        parsed = parse_pdb(
            conf.inference.input_pdb,
            parse_hetatom=False
        )
        xyz_fixed = parsed['xyz']      # å›ºå®šåŒºåŸŸåæ ‡
        seq_fixed = parsed['seq']      # å›ºå®šåŒºåŸŸåºåˆ—
    else:
        xyz_fixed = None
        seq_fixed = None

    # 2. è§£æcontigæ˜ å°„
    contig_map = ContigMap(
        parsed_pdb=parsed,
        contigs=conf.contigmap.contigs
    )

    # 3. ç¡®å®šè®¾è®¡é•¿åº¦
    L_total = contig_map.contig_length
    L_fixed = len(contig_map.receptor)
    L_design = L_total - L_fixed

    return {
        'xyz_fixed': xyz_fixed,
        'seq_fixed': seq_fixed,
        'contig_map': contig_map,
        'L_total': L_total
    }
```

---

## ğŸ”„ ç¬¬ä¸‰æ­¥ï¼šé‡‡æ ·å¾ªç¯

### 3.1 é‡‡æ ·åˆå§‹åŒ–

```python
def sample_init(self, L):
    """
    åˆå§‹åŒ–é‡‡æ ·çŠ¶æ€

    Args:
        L: è›‹ç™½è´¨é•¿åº¦

    Returns:
        åˆå§‹çŠ¶æ€å­—å…¸
    """

    # 1. ä»é«˜æ–¯å™ªå£°åˆå§‹åŒ–åæ ‡
    xyz_0 = torch.randn(1, L, 3) * 10.0  # æ ‡å‡†å·®10Ã…

    # 2. ä»å‡åŒ€åˆ†å¸ƒåˆå§‹åŒ–æ—‹è½¬
    R_0 = random_rotation(L)

    # 3. ç»„åˆä¸ºåˆšä½“å˜æ¢ï¼ˆframesï¼‰
    frames_0 = {
        'xyz': xyz_0,      # CAä½ç½®
        'R': R_0,          # å±€éƒ¨åæ ‡ç³»æ–¹å‘
    }

    # 4. åˆå§‹åŒ–åºåˆ—ï¼ˆå…¨éƒ¨maskï¼‰
    seq_0 = torch.full((1, L), 20)  # 20 = MASK_TOKEN

    # 5. åˆ›å»ºmaskï¼ˆå“ªäº›ä½ç½®éœ€è¦è®¾è®¡ï¼‰
    mask_design = torch.ones(1, L, dtype=torch.bool)
    if self.contig_map:
        # å›ºå®šåŒºåŸŸä¸è®¾è®¡
        mask_design[:, self.contig_map.receptor] = False

    return {
        'frames': frames_0,
        'seq': seq_0,
        'mask': mask_design,
        't': self.diffuser.T  # ä»æœ€å¤§å™ªå£°å¼€å§‹
    }
```

### 3.2 ä¸»é‡‡æ ·å¾ªç¯

```python
def sample(self, L, num_samples=1):
    """
    ä¸»é‡‡æ ·å‡½æ•°

    Args:
        L: è›‹ç™½è´¨é•¿åº¦
        num_samples: ç”Ÿæˆæ ·æœ¬æ•°
    """

    designs = []

    for n in range(num_samples):
        print(f"Generating design {n+1}/{num_samples}")

        # 1. åˆå§‹åŒ–
        state = self.sample_init(L)

        # 2. é‡‡æ ·å¾ªç¯ï¼ˆä»Tåˆ°1ï¼‰
        for t in reversed(range(1, self.diffuser.T + 1)):
            state['t'] = t

            # 2.1 å•æ­¥å»å™ª
            state = self.sample_step(state)

            # 2.2 å¯é€‰ï¼šä¿å­˜è½¨è¿¹
            if self.save_trajectory and t % 10 == 0:
                self.trajectory.append(state.copy())

            # 2.3 è¿›åº¦æ˜¾ç¤º
            if t % 20 == 0:
                print(f"  Step {self.diffuser.T - t}/{self.diffuser.T}")

        # 3. æœ€ç»ˆç»“æ„
        final_design = self.finalize(state)
        designs.append(final_design)

    return designs
```

### 3.3 å•æ­¥å»å™ªï¼ˆæ ¸å¿ƒï¼‰

```python
def sample_step(self, state):
    """
    å•æ­¥å»å™ª

    æµç¨‹:
    1. æ¨¡å‹å‰å‘ä¼ æ’­ï¼ˆé¢„æµ‹å™ªå£°ï¼‰
    2. è®¡ç®—å»å™ªæ–¹å‘
    3. ï¼ˆå¯é€‰ï¼‰åº”ç”¨åŠ¿èƒ½å¼•å¯¼
    4. æ›´æ–°çŠ¶æ€
    """

    frames_t = state['frames']
    seq = state['seq']
    t = state['t']

    # ===== æ­¥éª¤1: é¢„å¤„ç† =====
    # æ„å»ºæ¨¡å‹è¾“å…¥ç‰¹å¾
    msa_feat, pair_feat, xyz_feat = self._preprocess(
        frames_t, seq, t
    )

    # ===== æ­¥éª¤2: æ¨¡å‹é¢„æµ‹ =====
    with torch.no_grad():
        model_out = self.model(
            msa=msa_feat,
            pair=pair_feat,
            xyz=xyz_feat,
            t=t / self.diffuser.T  # å½’ä¸€åŒ–æ—¶é—´
        )

    # æ¨¡å‹è¾“å‡º
    score_trans = model_out['trans_score']  # å¹³ç§»è¯„åˆ†
    score_rot = model_out['rot_score']      # æ—‹è½¬è¯„åˆ†
    seq_logits = model_out['seq_logits']    # åºåˆ—é¢„æµ‹

    # ===== æ­¥éª¤3: åº”ç”¨åŠ¿èƒ½å¼•å¯¼ï¼ˆå¯é€‰ï¼‰=====
    if self.potential_manager:
        # è®¡ç®—åŠ¿èƒ½æ¢¯åº¦
        frames_t.requires_grad_(True)
        energy = self.potential_manager.compute_all_potentials(
            frames_t, t
        )
        grad_energy = torch.autograd.grad(energy, frames_t)[0]

        # å¼•å¯¼è¯„åˆ†
        guide_scale = self.potential_manager.get_guide_scale(t)
        score_trans = score_trans - guide_scale * grad_energy['trans']
        score_rot = score_rot - guide_scale * grad_energy['rot']

    # ===== æ­¥éª¤4: å»å™ªæ›´æ–° =====
    frames_t_minus_1 = self.diffuser.p_sample(
        x_t=frames_t,
        t=t,
        score={'trans': score_trans, 'rot': score_rot},
        temperature=self.temperature
    )

    # ===== æ­¥éª¤5: åºåˆ—æ›´æ–°ï¼ˆå¯é€‰ï¼‰=====
    if self.update_seq:
        seq_probs = F.softmax(seq_logits, dim=-1)
        seq = torch.multinomial(seq_probs.view(-1, 20), 1)
        seq = seq.view(1, -1)

    # ===== æ­¥éª¤6: å›ºå®šåŒºåŸŸï¼ˆæ”¯æ¶è®¾è®¡ï¼‰=====
    if self.contig_map:
        # ä¿æŒå›ºå®šåŒºåŸŸä¸å˜
        mask_fixed = ~state['mask']
        frames_t_minus_1['xyz'][mask_fixed] = self.xyz_fixed[mask_fixed]
        frames_t_minus_1['R'][mask_fixed] = self.R_fixed[mask_fixed]

    # æ›´æ–°çŠ¶æ€
    state['frames'] = frames_t_minus_1
    state['seq'] = seq
    state['t'] = t - 1

    return state
```

### 3.4 é¢„å¤„ç†è¯¦è§£

```python
def _preprocess(self, frames, seq, t):
    """
    æ„å»ºæ¨¡å‹è¾“å…¥ç‰¹å¾
    """
    B, L = seq.shape

    # 1. åºåˆ—ç‰¹å¾
    seq_1hot = F.one_hot(seq, num_classes=21)  # (B, L, 21)

    # 2. ä½ç½®ç¼–ç 
    pos_enc = positional_encoding(L, d_model=256)  # (L, 256)
    pos_enc = pos_enc.unsqueeze(0).expand(B, -1, -1)

    # 3. æ—¶é—´åµŒå…¥
    t_emb = timestep_embedding(t, dim=256)  # (256,)
    t_emb = t_emb.unsqueeze(0).unsqueeze(0).expand(B, L, -1)

    # 4. MSAç‰¹å¾ï¼ˆå•åºåˆ—æƒ…å†µï¼‰
    msa_feat = torch.cat([
        seq_1hot,
        pos_enc,
        t_emb
    ], dim=-1)  # (B, L, 21+256+256)
    msa_feat = msa_feat.unsqueeze(1)  # (B, 1, L, feat_dim)

    # 5. Pairç‰¹å¾
    # 5.1 ç›¸å¯¹ä½ç½®
    rel_pos = torch.arange(L)[:, None] - torch.arange(L)[None, :]
    rel_pos_feat = rbf_encode(rel_pos)  # (L, L, 36)

    # 5.2 ç›¸å¯¹æ–¹å‘ï¼ˆä»framesè®¡ç®—ï¼‰
    pair_feat = self._get_pair_features(frames)  # (B, L, L, feat_dim)

    # 5.3 ç»„åˆ
    pair_feat = torch.cat([
        rel_pos_feat.unsqueeze(0).expand(B, -1, -1, -1),
        pair_feat
    ], dim=-1)

    # 6. ç»“æ„ç‰¹å¾ï¼ˆxyzåæ ‡ï¼‰
    xyz_feat = frames['xyz']  # (B, L, 3)

    return msa_feat, pair_feat, xyz_feat
```

### 3.5 åéªŒé‡‡æ ·ï¼ˆDiffuserï¼‰

```python
# diffusion.py

class Diffuser:
    def p_sample(self, x_t, t, score, temperature=1.0):
        """
        åå‘é‡‡æ ·: x_t â†’ x_{t-1}

        åŸºäºDDPMå…¬å¼:
        x_{t-1} = Î¼(x_t, t) + Ïƒ(t) * z

        å…¶ä¸­:
        - Î¼: åéªŒå‡å€¼ï¼ˆä»scoreè®¡ç®—ï¼‰
        - Ïƒ: åéªŒæ ‡å‡†å·®
        - z: æ ‡å‡†é«˜æ–¯å™ªå£°
        """

        # 1. æå–å™ªå£°è°ƒåº¦å‚æ•°
        alpha_bar_t = self.alpha_bar[t]
        alpha_bar_t_minus_1 = self.alpha_bar[t-1] if t > 1 else 1.0
        beta_t = self.beta[t]

        # 2. è®¡ç®—åéªŒå‡å€¼
        # Î¼ = (1/âˆšÎ±_t) * (x_t - (Î²_t/âˆš(1-á¾±_t)) * score)
        coef1 = 1.0 / torch.sqrt(1.0 - beta_t)
        coef2 = beta_t / torch.sqrt(1.0 - alpha_bar_t)

        mu = coef1 * (x_t - coef2 * score)

        # 3. è®¡ç®—åéªŒæ ‡å‡†å·®
        sigma = torch.sqrt(
            (1.0 - alpha_bar_t_minus_1) / (1.0 - alpha_bar_t) * beta_t
        )

        # 4. é‡‡æ ·ï¼ˆt=1æ—¶ä¸åŠ å™ªå£°ï¼‰
        if t > 1:
            noise = torch.randn_like(x_t)
            x_t_minus_1 = mu + temperature * sigma * noise
        else:
            x_t_minus_1 = mu

        return x_t_minus_1

    def p_sample_rotation(self, R_t, t, score_rot, temperature=1.0):
        """
        æ—‹è½¬çš„åå‘é‡‡æ ·ï¼ˆåœ¨SO(3)ä¸Šï¼‰

        ä½¿ç”¨IGSO3åˆ†å¸ƒ
        """
        # 1. ä»è¯„åˆ†è®¡ç®—å»å™ªæ–¹å‘ï¼ˆåˆ‡ç©ºé—´ï¼‰
        omega = self.igso3.score_to_omega(score_rot, t)

        # 2. åœ¨SO(3)ä¸Šæ›´æ–°
        # R_{t-1} = R_t * Exp(Ïƒ(t) * omega + noise)
        sigma = self.igso3.sigma(t)

        if t > 1:
            noise_omega = temperature * torch.randn_like(omega)
            delta_R = so3_exp(sigma * omega + noise_omega)
        else:
            delta_R = so3_exp(sigma * omega)

        R_t_minus_1 = R_t @ delta_R

        return R_t_minus_1
```

---

## ğŸ¨ ç¬¬å››æ­¥ï¼šç‰¹æ®Šè®¾è®¡æ¨¡å¼

### 4.1 æ”¯æ¶å¼•å¯¼è®¾è®¡

```python
class ScaffoldedSampler(Sampler):
    """
    å›ºå®šéƒ¨åˆ†ç»“æ„ï¼Œè®¾è®¡å…¶ä½™éƒ¨åˆ†

    åº”ç”¨åœºæ™¯:
    - ç»“åˆä½ç‚¹è®¾è®¡ï¼šå›ºå®štargetï¼Œè®¾è®¡binder
    - ç‰‡æ®µåµŒå…¥ï¼šå›ºå®šmotifï¼Œè®¾è®¡å‘¨å›´æ”¯æ¶
    """

    def sample_step(self, state):
        # 1. æ­£å¸¸é¢„æµ‹
        state = super().sample_step(state)

        # 2. æ¢å¤å›ºå®šåŒºåŸŸ
        mask_fixed = self.contig_map.receptor

        # å¹³ç§»
        state['frames']['xyz'][:, mask_fixed] = self.xyz_scaffold[mask_fixed]

        # æ—‹è½¬
        state['frames']['R'][:, mask_fixed] = self.R_scaffold[mask_fixed]

        # åºåˆ—
        state['seq'][:, mask_fixed] = self.seq_scaffold[mask_fixed]

        return state
```

### 4.2 éƒ¨åˆ†æ‰©æ•£

```python
class PartialDiffusionSampler(Sampler):
    """
    ä¸ä»Tå¼€å§‹ï¼Œè€Œä»ä¸­é—´æŸä¸ªt_startå¼€å§‹

    ç”¨é€”:
    - ç»“æ„ä¼˜åŒ–ï¼št_startè¾ƒå°
    - å¤šæ ·æ€§ç”Ÿæˆï¼št_startè¾ƒå¤§
    """

    def sample_init(self, L):
        # 1. åŠ è½½åˆå§‹ç»“æ„
        xyz_init = self.initial_structure['xyz']

        # 2. æ·»åŠ éƒ¨åˆ†å™ªå£°ï¼ˆåˆ°t_startï¼‰
        t_start = self.partial_T
        frames_t = self.diffuser.q_sample(
            xyz_init,
            t=t_start
        )

        return {
            'frames': frames_t,
            't': t_start  # ä»è¿™é‡Œå¼€å§‹
        }
```

### 4.3 è‡ªæ¡ä»¶åŒ–

```python
class SelfConditioning(Sampler):
    """
    ä½¿ç”¨å‰ä¸€æ¬¡é¢„æµ‹ä½œä¸ºæ¡ä»¶

    æé«˜è´¨é‡ï¼Œä½†é€Ÿåº¦å‡åŠï¼ˆæ¯æ­¥2æ¬¡å‰å‘ï¼‰
    """

    def sample_step(self, state):
        frames_t = state['frames']
        t = state['t']

        # ç¬¬ä¸€æ¬¡é¢„æµ‹ï¼ˆæ— æ¡ä»¶ï¼‰
        with torch.no_grad():
            out_1 = self.model(
                frames=frames_t,
                t=t,
                self_cond=None
            )

        # ç¬¬äºŒæ¬¡é¢„æµ‹ï¼ˆä»¥ç¬¬ä¸€æ¬¡é¢„æµ‹ä¸ºæ¡ä»¶ï¼‰
        with torch.no_grad():
            out_2 = self.model(
                frames=frames_t,
                t=t,
                self_cond=out_1['frames_pred']
            )

        # ä½¿ç”¨ç¬¬äºŒæ¬¡é¢„æµ‹å»å™ª
        state['frames'] = self.diffuser.p_sample(
            frames_t, t, out_2['score']
        )

        return state
```

### 4.4 å¯¹ç§°è®¾è®¡

```python
class SymmetricSampler(Sampler):
    """
    è®¾è®¡å¯¹ç§°çš„è›‹ç™½è´¨å¤åˆç‰©
    """

    def __init__(self, conf, symdef='C3'):
        super().__init__(conf)
        self.symgen = SymGen(symdef)

        # åªè®¾è®¡asymmetric unit
        self.L_asu = conf.L_total // self.symgen.n_units

    def sample_init(self, L):
        # åˆå§‹åŒ–asymmetric unit
        state = super().sample_init(self.L_asu)

        # åº”ç”¨å¯¹ç§°ç”Ÿæˆå®Œæ•´å¤åˆç‰©
        state['frames_full'] = self.symgen.apply(state['frames'])

        return state

    def sample_step(self, state):
        # 1. åªå¯¹asymmetric unitå»å™ª
        frames_asu = state['frames'][:, :self.L_asu]

        # ... é¢„æµ‹å’Œå»å™ª ...

        # 2. åº”ç”¨å¯¹ç§°
        frames_full = self.symgen.apply(frames_asu)

        # 3. æ›´æ–°çŠ¶æ€
        state['frames'] = frames_asu
        state['frames_full'] = frames_full

        return state
```

---

## ğŸ” ç¬¬äº”æ­¥ï¼šåŠ¿èƒ½å¼•å¯¼

### 5.1 å¼•å¯¼åŸç†

åœ¨é‡‡æ ·è¿‡ç¨‹ä¸­ï¼Œé€šè¿‡åŠ¿èƒ½å‡½æ•°çš„æ¢¯åº¦å¼•å¯¼ç”Ÿæˆï¼š

```
score_guided = score_model - Î» * âˆ‡U(x)

å…¶ä¸­:
- score_model: æ¨¡å‹é¢„æµ‹çš„è¯„åˆ†
- U(x): åŠ¿èƒ½å‡½æ•°
- Î»: å¼•å¯¼å¼ºåº¦
```

### 5.2 åŠ¿èƒ½è®¡ç®—

```python
# åœ¨sample_stepä¸­

# 1. å…è®¸æ¢¯åº¦è®¡ç®—
frames_t = state['frames']
frames_t.requires_grad_(True)

# 2. è®¡ç®—æ‰€æœ‰åŠ¿èƒ½
total_energy = 0
for potential in self.potentials:
    if potential.is_active(t):
        energy = potential(frames_t)
        total_energy += potential.weight * energy

# 3. è®¡ç®—æ¢¯åº¦
grad_energy = torch.autograd.grad(
    total_energy,
    frames_t
)[0]

# 4. åº”ç”¨åˆ°è¯„åˆ†
guide_scale = get_guide_scale(t)
score_guided = score_model - guide_scale * grad_energy
```

### 5.3 å¸¸ç”¨åŠ¿èƒ½ç»„åˆ

#### ç»“åˆä½ç‚¹è®¾è®¡
```python
potentials = [
    "type:binder_ROG,weight:1.0,min_t:1,max_t:50",
    "type:binder_ncontacts,weight:3.0,min_t:1,max_t:40",
    "type:interface_ncontacts,weight:2.0,min_t:1,max_t:30",
]
```

#### å¯¹ç§°å¯¡èšä½“è®¾è®¡
```python
potentials = [
    "type:monomer_ROG,weight:1.0",
    "type:olig_contacts,weight:2.0,min_t:10,max_t:60",
]
```

---

## ğŸ“¤ ç¬¬å…­æ­¥ï¼šåå¤„ç†å’Œè¾“å‡º

### 6.1 æœ€ç»ˆåŒ–

```python
def finalize(self, state):
    """
    å®Œæˆé‡‡æ ·åçš„å¤„ç†
    """
    frames_final = state['frames']
    seq_final = state['seq']

    # 1. æ„å»ºå…¨åŸå­ç»“æ„
    xyz_allatom = build_full_structure(
        frames=frames_final,
        seq=seq_final
    )

    # 2. ä¾§é“¾ä¼˜åŒ–ï¼ˆå¯é€‰ï¼‰
    if self.optimize_sidechain:
        xyz_allatom = optimize_sidechains(
            xyz_allatom, seq_final
        )

    # 3. è¯„åˆ†
    scores = {}
    scores['rmsd'] = calc_rmsd(xyz_allatom, self.reference)
    scores['clash'] = calc_clashes(xyz_allatom)

    return {
        'xyz': xyz_allatom,
        'seq': seq_final,
        'scores': scores
    }
```

### 6.2 å†™å…¥PDB

```python
def save_design(design, output_path):
    """ä¿å­˜è®¾è®¡åˆ°PDBæ–‡ä»¶"""

    # 1. å†™ä¸»PDBæ–‡ä»¶
    writepdb(
        filename=f"{output_path}.pdb",
        atoms=design['xyz'],
        seq=design['seq']
    )

    # 2. å†™è½¨è¿¹ï¼ˆå¦‚æœæœ‰ï¼‰
    if 'trajectory' in design:
        writepdb_multi(
            filename=f"{output_path}_traj.pdb",
            atoms_stack=design['trajectory'],
            seq_stack=design['seq']
        )

    # 3. å†™å…ƒæ•°æ®
    metadata = {
        'sequence': seq_to_string(design['seq']),
        'length': len(design['seq']),
        'scores': design['scores'],
        'timestamp': datetime.now().isoformat()
    }

    with open(f"{output_path}_meta.json", 'w') as f:
        json.dump(metadata, f, indent=2)
```

---

## ğŸ“Š å®Œæ•´æ‰§è¡Œæ—¶é—´çº¿

### ç¤ºä¾‹ï¼šç”Ÿæˆ100æ®‹åŸºè›‹ç™½ï¼ˆ50æ­¥é‡‡æ ·ï¼‰

```
æ—¶é—´   æ“ä½œ                          GPUå†…å­˜    è¯´æ˜
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
0.0s   åŠ è½½é…ç½®å’Œæ¨¡å‹                  2GB      ä¸€æ¬¡æ€§
0.5s   â”œâ”€ åˆ›å»ºæ¨¡å‹å®ä¾‹
1.0s   â”œâ”€ åŠ è½½æƒé‡
1.2s   â””â”€ ç§»è‡³GPU

1.2s   åˆå§‹åŒ–é‡‡æ ·                      +1GB
1.3s   â”œâ”€ é‡‡æ ·åˆå§‹å™ªå£°
1.4s   â”œâ”€ æ„å»ºè¾“å…¥ç‰¹å¾
1.5s   â””â”€ åˆå§‹åŒ–çŠ¶æ€

1.5s   é‡‡æ ·å¾ªç¯å¼€å§‹                    +5GB     ä¸»è¦è®¡ç®—
3.0s   â”œâ”€ Step 50/50 (t=50)           å³°å€¼8GB
4.5s   â”œâ”€ Step 40/50 (t=40)
6.0s   â”œâ”€ Step 30/50 (t=30)                   æ¯æ­¥~30ms
7.5s   â”œâ”€ Step 20/50 (t=20)
9.0s   â”œâ”€ Step 10/50 (t=10)
10.5s  â””â”€ Step 1/50  (t=1)

10.5s  åå¤„ç†                          -4GB
11.0s  â”œâ”€ æ„å»ºå…¨åŸå­
11.3s  â”œâ”€ ä¾§é“¾ä¼˜åŒ–ï¼ˆå¯é€‰ï¼‰
11.5s  â””â”€ è¯„åˆ†

11.5s  å†™å…¥è¾“å‡º                        æ¸…ç†
11.7s  â”œâ”€ å†™PDB
11.8s  â”œâ”€ å†™è½¨è¿¹
11.9s  â””â”€ å†™å…ƒæ•°æ®

12.0s  å®Œæˆ                            é‡Šæ”¾GPU
```

### æ€§èƒ½å½±å“å› ç´ 

| å› ç´  | å½±å“ | ä¼˜åŒ–æ–¹æ³• |
|------|------|----------|
| è›‹ç™½è´¨é•¿åº¦ | O(LÂ²) | å‡å°‘é•¿åº¦ï¼Œåˆ†æ®µè®¾è®¡ |
| é‡‡æ ·æ­¥æ•° | çº¿æ€§ | å‡å°‘æ­¥æ•°ï¼ˆ50â†’25ï¼‰ |
| æ‰¹é‡å¤§å° | GPUå†…å­˜ | ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ |
| åŠ¿èƒ½å¼•å¯¼ | +20-50% | é™åˆ¶æ´»è·ƒæ—¶é—´çª—å£ |
| è‡ªæ¡ä»¶åŒ– | 2å€æ—¶é—´ | ä»…å…³é”®æ­¥éª¤ä½¿ç”¨ |

---

## ğŸ› è°ƒè¯•å’Œç›‘æ§

### å…³é”®æ£€æŸ¥ç‚¹

```python
# åœ¨sample_stepä¸­æ·»åŠ æ–­è¨€å’Œæ—¥å¿—

def sample_step(self, state):
    t = state['t']

    # æ£€æŸ¥1: åæ ‡èŒƒå›´
    xyz = state['frames']['xyz']
    assert xyz.abs().max() < 1000, f"åæ ‡çˆ†ç‚¸ at t={t}"

    # æ£€æŸ¥2: NaNæ£€æµ‹
    assert not torch.isnan(xyz).any(), f"NaNåæ ‡ at t={t}"

    # æ£€æŸ¥3: èƒ½é‡ç›‘æ§
    if t % 10 == 0:
        energy = self.potential_manager.compute_all_potentials(
            state['frames'], t
        )
        print(f"t={t}, energy={energy.item():.2f}")

    # ... æ­£å¸¸é‡‡æ · ...

    return state
```

### å¸¸è§é—®é¢˜å’Œè§£å†³

| é—®é¢˜ | åŸå›  | è§£å†³æ–¹æ³• |
|------|------|----------|
| åæ ‡çˆ†ç‚¸ | æ¢¯åº¦è¿‡å¤§ | å‡å°å­¦ä¹ ç‡/æ¸©åº¦ |
| NaNé”™è¯¯ | æ•°å€¼ä¸ç¨³å®š | å¢åŠ epsï¼Œæ£€æŸ¥é™¤é›¶ |
| GPU OOM | å†…å­˜ä¸è¶³ | å‡å°æ‰¹é‡ï¼Œæ¢¯åº¦æ£€æŸ¥ç‚¹ |
| ç»“æ„å´©æºƒ | å¼•å¯¼è¿‡å¼º | å‡å°åŠ¿èƒ½æƒé‡ |
| æ”¶æ•›æ…¢ | æ­¥æ•°ä¸è¶³ | å¢åŠ é‡‡æ ·æ­¥æ•° |

---

## ğŸ¯ ä¼˜åŒ–æŠ€å·§

### 1. å¿«é€ŸåŸå‹
```python
# ç”¨äºå¿«é€Ÿæµ‹è¯•
config = {
    'num_steps': 10,      # å°‘é‡æ­¥æ•°
    'num_designs': 1,     # å•ä¸ªæ ·æœ¬
    'L': 50,              # çŸ­åºåˆ—
}
```

### 2. ç”Ÿäº§æ¨¡å¼
```python
# ç”¨äºå®é™…è®¾è®¡
config = {
    'num_steps': 50,      # æ ‡å‡†æ­¥æ•°
    'num_designs': 100,   # æ‰¹é‡ç”Ÿæˆ
    'temperature': 1.0,   # æ ‡å‡†æ¸©åº¦
}
```

### 3. é«˜è´¨é‡æ¨¡å¼
```python
# ç”¨äºå…³é”®è®¾è®¡
config = {
    'num_steps': 200,         # æ›´å¤šæ­¥æ•°
    'self_conditioning': True, # è‡ªæ¡ä»¶åŒ–
    'optimize_sidechain': True,# ä¾§é“¾ä¼˜åŒ–
}
```

---

## ğŸ“š ä¸‹ä¸€æ­¥

- äº†è§£ [æ¨¡å‹æ¶æ„](./04_model_architecture.md) æ·±å…¥ç†è§£ç¥ç»ç½‘ç»œ
- é˜…è¯» [æ•°å­¦åŸç†](./05_mathematical_foundations.md) ç†è§£æ‰©æ•£æ¨¡å‹ç†è®º
- æŸ¥çœ‹ [æ ¸å¿ƒæ¨¡å—](./02_core_modules.md) äº†è§£å„ç»„ä»¶è¯¦æƒ…
